import requests
import time
import random
import re
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from webdriver_manager.chrome import ChromeDriverManager
from datetime import datetime
import oracledb  # Oracle DB ì—°ê²°ìš©
from elasticsearch import Elasticsearch
import csv
import json
import os
import pandas as pd

class KakaoMapReviewCrawler:
    def __init__(self):
        # Chrome ì˜µì…˜ ì„¤ì •
        self.chrome_options = webdriver.ChromeOptions()
        self.chrome_options.add_argument('--no-sandbox')
        self.chrome_options.add_argument('--disable-dev-shm-usage')
        self.chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        self.chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        self.chrome_options.add_experimental_option('useAutomationExtension', False)
        self.chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        # Windows í™˜ê²½ì—ì„œ ì¶”ê°€ ì˜µì…˜
        self.chrome_options.add_argument('--disable-gpu')
        self.chrome_options.add_argument('--disable-extensions')
        self.chrome_options.add_argument('--disable-plugins')
        self.chrome_options.add_argument('--disable-images')
        self.chrome_options.add_argument('--headless')  # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œë¡œ ì‹¤í–‰
        
        # ì¹´ì¹´ì˜¤ë§µ API ì„¤ì •
        self.kakao_api_key = "22a3f23874d2dacc284c6ab7eea89e10"  # ì‹¤ì œ API í‚¤
        self.kakao_search_url = "https://dapi.kakao.com/v2/local/search/keyword.json"
        self.kakao_place_url = "https://place.map.kakao.com/"
        
        # Oracle DB ì„¤ì •
        self.db_config = {
            'user': 'c##camp',
            'password': 'camp1234',
            'dsn': 'localhost:1521/xe'
        }
        
        # Elasticsearch ì„¤ì •
        self.es = Elasticsearch(['http://localhost:9200'])
        self.index_name = "reviews"
        
        # íŒŒì¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
        self.output_dir = "crawled_data"
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
        
        self.driver = None
        self.all_reviews = []  # ëª¨ë“  ë¦¬ë·°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        
    def read_camping_data_from_excel(self):
        """Excel íŒŒì¼ì—ì„œ ìº í•‘ì¥ ë°ì´í„° ì½ê¸°"""
        try:
            # Excel íŒŒì¼ ê²½ë¡œ
            excel_path = "../../camping_data.xlsx"
            
            # Excel íŒŒì¼ ì½ê¸°
            df = pd.read_excel(excel_path)
            
            print(f"Excel íŒŒì¼ ì½ê¸° ì„±ê³µ!")
            print(f"ì´ {len(df)}ê°œì˜ ìº í•‘ì¥ ë°ì´í„°ë¥¼ ì½ì–´ì™”ìŠµë‹ˆë‹¤.")
            
            camping_data = []
            for index, row in df.iterrows():
                camping_id = row['contentId']
                camping_name = row['facltNm']
                address = row['addr1'] if pd.notna(row['addr1']) else "ì£¼ì†Œ ì •ë³´ ì—†ìŒ"
                
                camping_data.append((camping_id, camping_name, address))
            
            print(f"ì´ {len(camping_data)}ê°œì˜ ìº í•‘ì¥ ë°ì´í„°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
            return camping_data
            
        except Exception as e:
            print(f"Excel íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            return []
    
    def connect_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        try:
            connection = oracledb.connect(**self.db_config)
            print("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ!")
            return connection
        except Exception as e:
            print(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            print("Oracle DB ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return None
    
    def check_elasticsearch_connection(self):
        """Elasticsearch ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            if self.es.ping():
                print("Elasticsearch ì—°ê²° ì„±ê³µ!")
                return True
            else:
                print("Elasticsearch ì—°ê²° ì‹¤íŒ¨!")
                return False
        except Exception as e:
            print(f"Elasticsearch ì—°ê²° ì˜¤ë¥˜: {e}")
            print("Elasticsearch ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return False
    
    def create_index_if_not_exists(self):
        """Elasticsearch ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒì„±"""
        if not self.es.indices.exists(index=self.index_name):
            mapping = {
                "mappings": {
                    "properties": {
                        "revId": {"type": "long"},
                        "contentId": {"type": "long"},
                        "memberId": {"type": "long"},
                        "writer": {
                            "type": "text",
                            "analyzer": "standard"
                        },
                        "content": {
                            "type": "text",
                            "analyzer": "standard"
                        },
                        "createdAt": {"type": "date"},
                        "updatedAt": {"type": "date"},
                        "score": {"type": "integer"},
                        "keywordIds": {"type": "long"},
                        "campingName": {
                            "type": "text",
                            "analyzer": "standard"
                        },
                        "source": {"type": "keyword"}
                    }
                }
            }
            self.es.indices.create(index=self.index_name, body=mapping)
            print(f"Elasticsearch ì¸ë±ìŠ¤ '{self.index_name}' ìƒì„± ì™„ë£Œ")
        else:
            print(f"Elasticsearch ì¸ë±ìŠ¤ '{self.index_name}' ì´ë¯¸ ì¡´ì¬")
    
    def search_kakao_place(self, camping_name):
        """ì¹´ì¹´ì˜¤ë§µ APIë¡œ ìº í•‘ì¥ ê²€ìƒ‰"""
        try:
            headers = {
                'Authorization': f'KakaoAK {self.kakao_api_key}'
            }
            
            params = {
                'query': camping_name,
                'category_group_code': 'AD5',  # ìˆ™ë°• ì¹´í…Œê³ ë¦¬
                'size': 1
            }
            
            print(f"ì¹´ì¹´ì˜¤ë§µ APIë¡œ ê²€ìƒ‰ ì¤‘: {camping_name}")
            response = requests.get(self.kakao_search_url, headers=headers, params=params)
            
            if response.status_code == 200:
                data = response.json()
                if data['documents']:
                    place = data['documents'][0]
                    place_id = place['id']
                    # ë¦¬ë·° í˜ì´ì§€ë¡œ ì§ì ‘ ì´ë™ (#comment ì¶”ê°€)
                    place_url = f"{self.kakao_place_url}{place_id}#comment"
                    print(f"ì¥ì†Œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤: {place['place_name']} (ID: {place_id})")
                    return place_url
                else:
                    print(f"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤: {camping_name}")
                    return None
            else:
                print(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"ì¹´ì¹´ì˜¤ë§µ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def extract_reviews(self, place_url):
        """ì¹´ì¹´ì˜¤ë§µì—ì„œ ë¦¬ë·° ì¶”ì¶œ (ë™ì  ë¡œë”© ì²˜ë¦¬)"""
        try:
            print(f"ë¦¬ë·° í˜ì´ì§€ ì ‘ì†: {place_url}")
            self.driver.get(place_url)
            time.sleep(random.uniform(5,8))  # ë¡œë”© ì‹œê°„ ì¦ê°€
            
            # í˜ì´ì§€ì˜ ëª¨ë“  iframe í™•ì¸
            iframes = self.driver.find_elements(By.TAG_NAME, "iframe")
            print(f"í˜ì´ì§€ì—ì„œ {len(iframes)}ê°œì˜ iframeì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            
            # iframeìœ¼ë¡œ ì „í™˜ ì‹œë„
            iframe_found = False
            for iframe in iframes:
                try:
                    iframe_id = iframe.get_attribute("id")
                    if iframe_id and ("entry" in iframe_id.lower() or "review" in iframe_id.lower()):
                        self.driver.switch_to.frame(iframe)
                        print(f"iframe {iframe_id}ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")
                        iframe_found = True
                        break
                except:
                    continue
            
            if not iframe_found:
                print("ì ì ˆí•œ iframeì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í˜ì´ì§€ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
            
            # ë¦¬ë·° ê´€ë ¨ ìš”ì†Œê°€ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "li.item_evaluation"))
                )
                print("ë¦¬ë·° ìš”ì†Œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            except TimeoutException:
                print("ë¦¬ë·° ìš”ì†Œ ë¡œë”© ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼")
            
            reviews = []
            page = 1
            max_pages = 3 # ìµœëŒ€ 3í˜ì´ì§€ê¹Œì§€ ìˆ˜ì§‘
            
            while page <= max_pages:
                try:
                    # ì‹¤ì œ ì¹´ì¹´ì˜¤ë§µ ë¦¬ë·° êµ¬ì¡°ì— ë§ëŠ” ì„ íƒì
                    review_elements = self.driver.find_elements(By.CSS_SELECTOR, "ul.list_review > li")
                    if not review_elements:
                        print("ë¦¬ë·° ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        # í˜ì´ì§€ ì†ŒìŠ¤ì—ì„œ ë¦¬ë·° ê´€ë ¨ í…ìŠ¤íŠ¸ í™•ì¸
                        page_source = self.driver.page_source
                        if "í›„ê¸°" in page_source:
                            print("í˜ì´ì§€ì— 'í›„ê¸°' í…ìŠ¤íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤.")
                        if "í‰ì " in page_source:
                            print("í˜ì´ì§€ì— 'í‰ì ' í…ìŠ¤íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤.")
                        if "ë³„ì " in page_source:
                            print("í˜ì´ì§€ì— 'ë³„ì ' í…ìŠ¤íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤.")
                        break
                    print(f"í˜ì´ì§€ {page}ì—ì„œ {len(review_elements)}ê°œì˜ ë¦¬ë·°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    for element in review_elements:
                        try:
                            # ë¦¬ë·° í…ìŠ¤íŠ¸ ì •ì œ - ì‹¤ì œ ë¦¬ë·° ë‚´ìš©ë§Œ ì¶”ì¶œ
                            try:
                                inner_review = element.find_element(By.CSS_SELECTOR, "div.inner_review")
                                review_text = inner_review.text.strip()
                            except:
                                # div.inner_reviewê°€ ì—†ìœ¼ë©´ li ìš”ì†Œì—ì„œ ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                                review_text = element.text.strip()
                            
                            # ë¦¬ë·° í…ìŠ¤íŠ¸ ì •ì œ (ì‚¬ìš©ì ì •ë³´ ì œê±°)
                            if review_text:
                                # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬
                                lines = review_text.split('\n')
                                cleaned_lines = []
                                
                                # ì‚¬ìš©ì ì •ë³´ íŒ¨í„´ ì œê±°
                                skip_patterns = [
                                    'ê³¨ë“œ ë ˆë²¨', 'ì‹¤ë²„ ë ˆë²¨', 'ë¸Œë¡ ì¦ˆ ë ˆë²¨',
                                    'í›„ê¸°', 'ë³„ì í‰ê· ', 'íŒ”ë¡œì›Œ',
                                    'ë©”ë‰´ ë”ë³´ê¸°', 'ë ˆë²¨'
                                ]
                                
                                for line in lines:
                                    line = line.strip()
                                    if not line:
                                        continue
                                    
                                    # ì‚¬ìš©ì ì •ë³´ íŒ¨í„´ì´ í¬í•¨ëœ ì¤„ ì œì™¸
                                    skip_line = False
                                    for pattern in skip_patterns:
                                        if pattern in line:
                                            skip_line = True
                                            break
                                    
                                    # ìˆ«ìë§Œ ìˆëŠ” ì¤„ ì œì™¸ (ë ˆë²¨ ë²ˆí˜¸ ë“±)
                                    if line.isdigit() and len(line) <= 3:
                                        skip_line = True
                                    
                                    # ë‚ ì§œ íŒ¨í„´ ì œì™¸ (YYYY.MM.DD)
                                    if re.match(r'\d{4}\.\d{2}\.\d{2}', line):
                                        skip_line = True
                                    
                                    if not skip_line:
                                        cleaned_lines.append(line)
                                
                                # ì •ì œëœ ë¦¬ë·° í…ìŠ¤íŠ¸ ìƒì„±
                                review_text = ' '.join(cleaned_lines).strip()
                                
                                # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì œì™¸ (10ì ë¯¸ë§Œ)
                                if len(review_text) < 10:
                                    review_text = ""
                            
                            # ë³„ì  - figure_star on í´ë˜ìŠ¤ ê°œìˆ˜ë¡œ ê³„ì‚°
                            rating = 0
                            try:
                                # figure_star on í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ìš”ì†Œë“¤ ì°¾ê¸°
                                star_elements = element.find_elements(By.CSS_SELECTOR, "span.figure_star.on")
                                if star_elements:
                                    rating = len(star_elements)
                                    print(f"ë³„ì  ì¶”ì¶œ ì„±ê³µ: {rating}ì  ({len(star_elements)}ê°œ ë³„)")
                                else:
                                    # ë‹¤ë¥¸ ë³„ì  ì„ íƒìë“¤ë„ ì‹œë„
                                    rating_selectors = [
                                        "span.ico_star",
                                        ".ico_star",
                                        ".star_score",
                                        ".rating",
                                        "[aria-label*='ë³„']",
                                        ".star",
                                        "span[class*='star']",
                                        "i[class*='star']",
                                        ".ico_star_on",
                                        ".ico_star_off",
                                        "span[class*='ico_star']",
                                        "i[class*='ico_star']",
                                        ".star_rating",
                                        ".review_star"
                                    ]
                                    
                                    for rating_selector in rating_selectors:
                                        try:
                                            rating_elements = element.find_elements(By.CSS_SELECTOR, rating_selector)
                                            if rating_elements:
                                                print(f"ë³„ì  ìš”ì†Œ ë°œê²¬: {rating_selector} (ê°œìˆ˜: {len(rating_elements)})")
                                                for rating_element in rating_elements:
                                                    rating_text = rating_element.get_attribute("aria-label")
                                                    if not rating_text:
                                                        rating_text = rating_element.get_attribute("title")
                                                    if not rating_text:
                                                        rating_text = rating_element.get_attribute("alt")
                                                    if not rating_text:
                                                        rating_text = rating_element.text
                                                    
                                                    if rating_text:
                                                        # ìˆ«ì ì¶”ì¶œ (1-5 ë²”ìœ„)
                                                        match = re.search(r'(\d+)', rating_text)
                                                        if match:
                                                            temp_rating = int(match.group(1))
                                                            if 1 <= temp_rating <= 5:
                                                                rating = temp_rating
                                                                print(f"ë³„ì  ì¶”ì¶œ ì„±ê³µ: {rating}")
                                                                break
                                                    
                                                    # í´ë˜ìŠ¤ëª…ì—ì„œ ë³„ì  ì •ë³´ ì¶”ì¶œ
                                                    class_name = rating_element.get_attribute("class")
                                                    if class_name:
                                                        # ico_star_on ê°œìˆ˜ë¡œ ë³„ì  ê³„ì‚°
                                                        if "ico_star_on" in class_name:
                                                            on_count = class_name.count("ico_star_on")
                                                            if on_count > 0:
                                                                rating = on_count
                                                                print(f"í´ë˜ìŠ¤ì—ì„œ ë³„ì  ì¶”ì¶œ: {rating}")
                                                                break
                                                if rating > 0:
                                                    break
                                        except Exception as e:
                                            continue
                            except Exception as e:
                                print(f"ë³„ì  ì¶”ì¶œ ì˜¤ë¥˜: {e}")
                            
                            # ë‚ ì§œ - ë” ì •í™•í•œ ì„ íƒì ì‚¬ìš©
                            date_text = "ë‚ ì§œ ì •ë³´ ì—†ìŒ"
                            date_selectors = [
                                "span.time_write",
                                ".time_write",
                                ".date",
                                ".time",
                                ".txt_date",
                                "span[class*='date']",
                                "span[class*='time']"
                            ]
                            
                            for date_selector in date_selectors:
                                try:
                                    date_element = element.find_element(By.CSS_SELECTOR, date_selector)
                                    date_text = date_element.text.strip()
                                    if date_text:
                                        break
                                except:
                                    continue
                            
                            # ì‘ì„±ìëª… ì¶”ì¶œ
                            writer = "ì¹´ì¹´ì˜¤ë§µì‚¬ìš©ì"
                            writer_selectors = [
                                "span.name",
                                ".name",
                                ".writer",
                                ".author",
                                "span[class*='name']",
                                "span[class*='writer']",
                                ".user_name",
                                ".reviewer"
                            ]
                            
                            for writer_selector in writer_selectors:
                                try:
                                    writer_element = element.find_element(By.CSS_SELECTOR, writer_selector)
                                    writer_text = writer_element.text.strip()
                                    if writer_text and len(writer_text) > 1:
                                        writer = writer_text
                                        break
                                except:
                                    continue
                            
                            if review_text and len(review_text) > 10:
                                reviews.append({
                                    'content': review_text,
                                    'rating': rating,
                                    'created_date': date_text,
                                    'writer': writer
                                })
                                print(f"ë¦¬ë·° ìˆ˜ì§‘: {writer} - {review_text[:50]}... (í‰ì : {rating})")
                        except Exception as e:
                            print(f"ë¦¬ë·° íŒŒì‹± ì˜¤ë¥˜: {e}")
                            continue
                    # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™ (ì¹´ì¹´ì˜¤ë§µì€ ìŠ¤í¬ë¡¤ ë°©ì‹ì¼ ìˆ˜ ìˆìŒ, ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ 1í˜ì´ì§€ë§Œ)
                    break
                except Exception as e:
                    print(f"ë¦¬ë·° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
                    break
            
            # iframeì—ì„œ ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³µê·€
            self.driver.switch_to.default_content()
            print(f"ì´ {len(reviews)}ê°œì˜ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
            return reviews
        except Exception as e:
            print(f"ë¦¬ë·° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³µê·€
            try:
                self.driver.switch_to.default_content()
            except:
                pass
            return []
    
    def save_reviews(self, camping_id, camping_name, reviews):
        """ë¦¬ë·°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì™€ Elasticsearchì— ì €ì¥"""
        if not reviews:
            print("ì €ì¥í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 1. Oracle DBì— ì €ì¥
        connection = self.connect_database()
        if connection:
            try:
                with connection.cursor() as cursor:
                    for review in reviews:
                        # ì‘ì„±ìëª… ê¸¸ì´ ì œí•œ (20ì)
                        writer = review.get('writer', 'ì¹´ì¹´ì˜¤ë§µì‚¬ìš©ì')
                        if len(writer) > 20:
                            writer = writer[:20]
                            print(f"ì‘ì„±ìëª…ì´ 20ìë¥¼ ì´ˆê³¼í•˜ì—¬ '{writer}'ë¡œ ì˜ë¼ëƒˆìŠµë‹ˆë‹¤.")
                        
                        # Oracle DBìš© ì¿¼ë¦¬ (ì‹¤ì œ í…Œì´ë¸” êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
                        sql = """
                        INSERT INTO review (rev_id, content_id, member_id, writer, content, score)
                        VALUES (review_rev_id_seq.NEXTVAL, :1, :2, :3, :4, :5)
                        """
                        cursor.execute(sql, (
                            camping_id,
                            1,  # member_idëŠ” ì„ì‹œë¡œ 1ë¡œ ì„¤ì •
                            writer,
                            review['content'],
                            review['rating']
                        ))
                
                connection.commit()
                print(f"ìº í•‘ì¥ ID {camping_id}: {len(reviews)}ê°œ ë¦¬ë·° DB ì €ì¥ ì™„ë£Œ")
                
            except Exception as e:
                print(f"DB ë¦¬ë·° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
                connection.rollback()
            finally:
                connection.close()
        else:
            print("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ë¡œ DB ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            print(f"ìˆ˜ì§‘ëœ ë¦¬ë·° {len(reviews)}ê°œ:")
            for i, review in enumerate(reviews[:3], 1):  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
                print(f"  {i}. í‰ì : {review['rating']}, ë‚´ìš©: {review['content'][:50]}...")
        
        # 2. Elasticsearchì— ì €ì¥
        try:
            # Elasticsearch ì¸ë±ìŠ¤ ìƒì„± í™•ì¸
            self.create_index_if_not_exists()
            
            for i, review in enumerate(reviews):
                # ì‘ì„±ìëª… ê¸¸ì´ ì œí•œ (20ì)
                writer = review.get('writer', 'ì¹´ì¹´ì˜¤ë§µì‚¬ìš©ì')
                if len(writer) > 20:
                    writer = writer[:20]
                
                # Elasticsearch ë¬¸ì„œ ìƒì„±
                doc = {
                    'revId': None,  # Elasticsearchì—ì„œ ìë™ ìƒì„±
                    'contentId': camping_id,
                    'memberId': 1,  # ì„ì‹œ member_id
                    'writer': writer,
                    'content': review['content'],
                    'createdAt': datetime.now().isoformat(),
                    'updatedAt': datetime.now().isoformat(),
                    'score': review['rating'],
                    'keywordIds': [],
                    'campingName': camping_name,
                    'source': 'kakao_map'
                }
                
                # Elasticsearchì— ì €ì¥
                response = self.es.index(index=self.index_name, body=doc)
                print(f"Elasticsearch ë¦¬ë·° {i+1} ì €ì¥ ì™„ë£Œ: {response['result']} (ID: {response['_id']})")
            
            # ì¸ë±ìŠ¤ ìƒˆë¡œê³ ì¹¨
            self.es.indices.refresh(index=self.index_name)
            print(f"ìº í•‘ì¥ '{camping_name}': {len(reviews)}ê°œ ë¦¬ë·° Elasticsearch ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            print(f"Elasticsearch ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def save_to_csv(self, reviews, camping_id, camping_name):
        """ë¦¬ë·°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{self.output_dir}/reviews_{camping_id}_{timestamp}.csv"
        
        try:
            with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
                fieldnames = ['camping_id', 'camping_name', 'writer', 'content', 'rating', 'created_date', 'crawled_at']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for review in reviews:
                    writer.writerow({
                        'camping_id': camping_id,
                        'camping_name': camping_name,
                        'writer': review.get('writer', 'ì¹´ì¹´ì˜¤ë§µì‚¬ìš©ì'),
                        'content': review['content'],
                        'rating': review['rating'],
                        'created_date': review.get('created_date', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'),
                        'crawled_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    })
            
            print(f"ğŸ“„ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
            return filename
            
        except Exception as e:
            print(f"âŒ CSV íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def save_to_json(self, reviews, camping_id, camping_name):
        """ë¦¬ë·°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{self.output_dir}/reviews_{camping_id}_{timestamp}.json"
        
        try:
            data = {
                'camping_info': {
                    'camping_id': camping_id,
                    'camping_name': camping_name,
                    'total_reviews': len(reviews),
                    'crawled_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                },
                'reviews': []
            }
            
            for review in reviews:
                data['reviews'].append({
                    'writer': review.get('writer', 'ì¹´ì¹´ì˜¤ë§µì‚¬ìš©ì'),
                    'content': review['content'],
                    'rating': review['rating'],
                    'created_date': review.get('created_date', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')
                })
            
            with open(filename, 'w', encoding='utf-8') as jsonfile:
                json.dump(data, jsonfile, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“„ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
            return filename
            
        except Exception as e:
            print(f"âŒ JSON íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def save_all_reviews_to_files(self):
        """ëª¨ë“  ìˆ˜ì§‘ëœ ë¦¬ë·°ë¥¼ í†µí•© íŒŒì¼ë¡œ ì €ì¥"""
        if not self.all_reviews:
            print("âŒ ì €ì¥í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # í†µí•© CSV íŒŒì¼ ì €ì¥
        csv_filename = f"{self.output_dir}/all_reviews_{timestamp}.csv"
        try:
            with open(csv_filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
                fieldnames = ['camping_id', 'camping_name', 'writer', 'content', 'rating', 'created_date', 'crawled_at']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for review_data in self.all_reviews:
                    writer.writerow(review_data)
            
            print(f"ğŸ“„ í†µí•© CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_filename}")
            
        except Exception as e:
            print(f"âŒ í†µí•© CSV íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # í†µí•© JSON íŒŒì¼ ì €ì¥
        json_filename = f"{self.output_dir}/all_reviews_{timestamp}.json"
        try:
            data = {
                'summary': {
                    'total_reviews': len(self.all_reviews),
                    'total_campings': len(set(review['camping_id'] for review in self.all_reviews)),
                    'crawled_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                },
                'reviews': self.all_reviews
            }
            
            with open(json_filename, 'w', encoding='utf-8') as jsonfile:
                json.dump(data, jsonfile, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“„ í†µí•© JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {json_filename}")
            
        except Exception as e:
            print(f"âŒ í†µí•© JSON íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def run(self, start_index=0, end_index=None):
        """í¬ë¡¤ë§ ì‹¤í–‰"""
        print("ì¹´ì¹´ì˜¤ë§µ ë¦¬ë·° í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # Elasticsearch ì—°ê²° í™•ì¸ (ì„ íƒì‚¬í•­)
        if not self.check_elasticsearch_connection():
            print("Elasticsearch ì—°ê²° ì‹¤íŒ¨. DBì—ë§Œ ì €ì¥ë©ë‹ˆë‹¤.")
        
        try:
            # í¬ë¡¬ë“œë¼ì´ë²„ ì„¤ì • (ë¡œì»¬ chromedriver.exe ì‚¬ìš©)
            print("í¬ë¡¬ë“œë¼ì´ë²„ë¥¼ ì„¤ì •í•˜ëŠ” ì¤‘...")
            try:
                # ë¡œì»¬ chromedriver.exe ì‚¬ìš©
                chromedriver_path = r"../../chromedriver.exe"
                service = Service(chromedriver_path)
                self.driver = webdriver.Chrome(service=service, options=self.chrome_options)
                print("í¬ë¡¬ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ!")
            except Exception as e:
                print(f"ë¡œì»¬ ChromeDriver ì„¤ì • ì‹¤íŒ¨: {e}")
                print("webdriver-managerë¡œ ì‹œë„í•©ë‹ˆë‹¤...")
                try:
                    service = Service(ChromeDriverManager().install())
                    self.driver = webdriver.Chrome(service=service, options=self.chrome_options)
                    print("webdriver-managerë¡œ í¬ë¡¬ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ!")
                except Exception as e2:
                    print(f"webdriver-managerë„ ì‹¤íŒ¨: {e2}")
                    print("Chrome ë¸Œë¼ìš°ì €ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    return
            
            # Excel íŒŒì¼ì—ì„œ ìº í•‘ì¥ ë°ì´í„° ì½ê¸°
            camping_sites = self.read_camping_data_from_excel()
            
            if not camping_sites:
                print("ìº í•‘ì¥ ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ì¸ë±ìŠ¤ ë²”ìœ„ ì„¤ì •
            if end_index is None:
                end_index = len(camping_sites)
            
            camping_sites = camping_sites[start_index:end_index]
            
            print(f"ì´ {len(camping_sites)}ê°œì˜ ìº í•‘ì¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. (ì¸ë±ìŠ¤: {start_index}~{end_index-1})")
            
            for i, (camping_id, camping_name, address) in enumerate(camping_sites, 1):
                print(f"[{i}/{len(camping_sites)}] {camping_name} ì²˜ë¦¬ ì¤‘...")
                
                # ì¹´ì¹´ì˜¤ë§µì—ì„œ ìº í•‘ì¥ ê²€ìƒ‰
                place_url = self.search_kakao_place(camping_name)
                if not place_url:
                    print(f" - {camping_name}: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                    continue
                
                # ë¦¬ë·° ì¶”ì¶œ
                reviews = self.extract_reviews(place_url)
                if not reviews:
                    print(f" - {camping_name}: ë¦¬ë·° ì—†ìŒ")
                    continue
                
                print(f" - {camping_name}: {len(reviews)}ê°œ ë¦¬ë·° ìˆ˜ì§‘")
                
                # ë°ì´í„°ë² ì´ìŠ¤ì™€ Elasticsearchì— ì €ì¥
                self.save_reviews(camping_id, camping_name, reviews)
                
                # ê°œë³„ ìº í•‘ì¥ CSV/JSON íŒŒì¼ ì €ì¥
                self.save_to_csv(reviews, camping_id, camping_name)
                self.save_to_json(reviews, camping_id, camping_name)
                
                # ì „ì²´ ë¦¬ë·° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                for review in reviews:
                    self.all_reviews.append({
                        'camping_id': camping_id,
                        'camping_name': camping_name,
                        'writer': review.get('writer', 'ì¹´ì¹´ì˜¤ë§µì‚¬ìš©ì'),
                        'content': review['content'],
                        'rating': review['rating'],
                        'created_date': review.get('created_date', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ'),
                        'crawled_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    })
                
                # ìš”ì²­ ê°„ê²© ì¡°ì ˆ
                time.sleep(random.uniform(5, 10))
            
            # í†µí•© íŒŒì¼ ì €ì¥
            if self.all_reviews:
                print(f"\nğŸ“Š ì´ {len(self.all_reviews)}ê°œ ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ!")
                self.save_all_reviews_to_files()
                
        except Exception as e:
            print(f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            if self.driver:
                self.driver.quit()
            print("í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    crawler = KakaoMapReviewCrawler()
    # ì „ì²´ ë°ì´í„° í¬ë¡¤ë§ (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)
    # crawler.run()
    
    # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì²˜ìŒ 5ê°œë§Œ í¬ë¡¤ë§
    crawler.run(start_index=0, end_index=5) 