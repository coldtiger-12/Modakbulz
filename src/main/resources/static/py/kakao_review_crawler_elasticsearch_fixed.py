from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
import time
import re
import random
from datetime import datetime
from elasticsearch import Elasticsearch
import csv
import json
import os
import requests
import pandas as pd
import argparse

class SimpleMoreCrawler:
    def __init__(self):
        # Chrome ì˜µì…˜ ì„¤ì •
        self.chrome_options = webdriver.ChromeOptions()
        self.chrome_options.add_argument('--no-sandbox')
        self.chrome_options.add_argument('--disable-dev-shm-usage')
        self.chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        self.chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        self.chrome_options.add_experimental_option('useAutomationExtension', False)
        self.chrome_options.add_argument('--headless')  # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ
        
        # Elasticsearch ì„¤ì •
        self.es = Elasticsearch(['http://localhost:9200'])
        self.index_name = "reviews"
        
        # íŒŒì¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
        self.output_dir = "crawled_data"
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
        
        self.driver = None
        
    def extract_reviews_with_more(self, place_url):
        """ë”ë³´ê¸° ë²„íŠ¼ì„ í´ë¦­í•´ì„œ ì „ì²´ ë¦¬ë·° ë‚´ìš© ì¶”ì¶œ"""
        try:
            print(f"ë¦¬ë·° í˜ì´ì§€ ì ‘ì†: {place_url}")
            self.driver.get(place_url)
            time.sleep(5)
            
            # ë¦¬ë·° ìš”ì†Œ ì°¾ê¸°
            review_elements = self.driver.find_elements(By.CSS_SELECTOR, "ul.list_review > li")
            print(f"ë¦¬ë·° ê°œìˆ˜: {len(review_elements)}")
            
            reviews = []
            for i, element in enumerate(review_elements[:5]):  # ì²˜ìŒ 5ê°œë§Œ í…ŒìŠ¤íŠ¸
                print(f"\n=== ë¦¬ë·° {i+1} ===")
                
                # ë”ë³´ê¸° ë²„íŠ¼ ì°¾ê¸°
                more_button = None
                more_button_selectors = [
                    "span.btn_more",
                    "button.btn_more", 
                    ".btn_more",
                    ".more_btn",
                    "[class*='more']",
                    "button[class*='more']",
                    ".btn_more_review",
                    ".more_text",
                    "span.more",
                    "a.more"
                ]
                
                # ë”ë³´ê¸° ë²„íŠ¼ ì°¾ê¸°
                for selector in more_button_selectors:
                    try:
                        more_button = element.find_element(By.CSS_SELECTOR, selector)
                        if more_button and more_button.is_displayed():
                            print(f"ë”ë³´ê¸° ë²„íŠ¼ ë°œê²¬: {selector}")
                            break
                    except:
                        continue
                
                # ë”ë³´ê¸° ë²„íŠ¼ì´ ìˆìœ¼ë©´ í´ë¦­
                if more_button:
                    print("ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­í•©ë‹ˆë‹¤.")
                    more_button.click()
                    time.sleep(3)  # ë‚´ìš© ë¡œë”© ëŒ€ê¸°
                
                # ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë”ë³´ê¸° í´ë¦­ í›„ ì „ì²´ ë‚´ìš©)
                try:
                    desc_review = element.find_element(By.CSS_SELECTOR, "p.desc_review")
                    review_text = desc_review.text.strip()
                    print(f"ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ: {review_text[:100]}...")
                except:
                    try:
                        inner_review = element.find_element(By.CSS_SELECTOR, "div.inner_review")
                        review_text = inner_review.text.strip()
                        print(f"ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ (fallback): {review_text[:100]}...")
                    except:
                        review_text = element.text.strip()
                        print(f"ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ (fallback2): {review_text[:100]}...")
                
                # í‚¤ì›Œë“œ ì ìˆ˜ ì¶”ì¶œ ë° ë¦¬ë·° í…ìŠ¤íŠ¸ ì •ì œ
                keyword_scores = {}
                if review_text:
                    # í‚¤ì›Œë“œ ì ìˆ˜ íŒ¨í„´ ì°¾ê¸° (ì˜ˆ: "ì‹œì„¤ ë·° +3", "ê°€ê²© ì‹œì„¤ +2" ë“±)
                    keyword_patterns = [
                        r'ì‹œì„¤\s*ì£¼ì°¨\s*\+(\d+)',
                        r'ê°€ê²©\s*ì‹œì„¤\s*\+(\d+)',
                        r'ê°€ê²©\s*ë·°\s*\+(\d+)',
                        r'ì‹œì„¤\s*\+(\d+)',
                        r'ì£¼ì°¨\s*\+(\d+)',
                        r'ì²­ê²°\s*\+(\d+)',
                        r'ê°€ê²©\s*\+(\d+)',
                        r'ë·°\s*\+(\d+)',
                        r'ìœ„ì¹˜\s*\+(\d+)',
                        r'ì„œë¹„ìŠ¤\s*\+(\d+)',
                        r'ë¶„ìœ„ê¸°\s*\+(\d+)',
                        r'í¸ì˜ì‹œì„¤\s*\+(\d+)'
                    ]
                    
                    # í‚¤ì›Œë“œ ì ìˆ˜ ì¶”ì¶œ
                    for pattern in keyword_patterns:
                        matches = re.findall(pattern, review_text)
                        if matches:
                            # íŒ¨í„´ì—ì„œ í‚¤ì›Œë“œ ì´ë¦„ ì¶”ì¶œ
                            if 'ì‹œì„¤' in pattern and 'ì£¼ì°¨' in pattern:
                                keyword_scores['ì‹œì„¤'] = 5  # ê¸°ë³¸ê°’
                                keyword_scores['ì£¼ì°¨'] = 5  # ê¸°ë³¸ê°’
                            elif 'ê°€ê²©' in pattern and 'ì‹œì„¤' in pattern:
                                keyword_scores['ê°€ê²©'] = 5  # ê¸°ë³¸ê°’
                                keyword_scores['ì‹œì„¤'] = 5  # ê¸°ë³¸ê°’
                            elif 'ê°€ê²©' in pattern and 'ë·°' in pattern:
                                keyword_scores['ê°€ê²©'] = 5  # ê¸°ë³¸ê°’
                                keyword_scores['ë·°'] = 5  # ê¸°ë³¸ê°’
                            else:
                                # ë‹¨ì¼ í‚¤ì›Œë“œ íŒ¨í„´
                                keyword_name = pattern.split(r'\s*\+(\d+)')[0].strip()
                                keyword_score = 5  # ê¸°ë³¸ê°’
                                keyword_scores[keyword_name] = keyword_score
                            
                            print(f"í‚¤ì›Œë“œ ì ìˆ˜ ë°œê²¬: {pattern} -> {keyword_scores}")
                            break
                    
                    # í‚¤ì›Œë“œ ì ìˆ˜ê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì‹œë„
                    if not keyword_scores:
                        # í‚¤ì›Œë“œ ì ìˆ˜ ìš”ì†Œë“¤ ì°¾ê¸°
                        keyword_selectors = [
                            "div.wrap_badge",
                            ".wrap_badge",
                            ".badge",
                            "span[class*='badge']",
                            "div[class*='keyword']",
                            ".keyword_score",
                            ".review_keyword"
                        ]
                        
                        for keyword_selector in keyword_selectors:
                            try:
                                keyword_elements = element.find_elements(By.CSS_SELECTOR, keyword_selector)
                                if keyword_elements:
                                    print(f"í‚¤ì›Œë“œ ìš”ì†Œ ë°œê²¬: {keyword_selector} (ê°œìˆ˜: {len(keyword_elements)})")
                                    
                                    for keyword_element in keyword_elements:
                                        keyword_text = keyword_element.text.strip()
                                        if keyword_text:
                                            print(f"í‚¤ì›Œë“œ í…ìŠ¤íŠ¸: {keyword_text}")
                                            
                                            # ì—¬ëŸ¬ ì¤„ë¡œ ë¶„ë¦¬ëœ í‚¤ì›Œë“œ í…ìŠ¤íŠ¸ ì²˜ë¦¬
                                            lines = keyword_text.split('\n')
                                            print(f"ë¶„ë¦¬ëœ ë¼ì¸ë“¤: {lines}")
                                            
                                            for line in lines:
                                                line = line.strip()
                                                if not line:
                                                    continue
                                                
                                                print(f"ì²˜ë¦¬ ì¤‘ì¸ ë¼ì¸: '{line}'")
                                                
                                                # í‚¤ì›Œë“œì™€ ì ìˆ˜ ë¶„ë¦¬
                                                # ì˜ˆ: "ì‹œì„¤ 5", "ì£¼ì°¨ 4", "ì²­ê²° 5" ë“±
                                                keyword_match = re.match(r'([ê°€-í£]+)\s*(\d+)', line)
                                                if keyword_match:
                                                    keyword_name = keyword_match.group(1)
                                                    keyword_score = int(keyword_match.group(2))
                                                    keyword_scores[keyword_name] = keyword_score
                                                    print(f"í‚¤ì›Œë“œ ì ìˆ˜ ì¶”ì¶œ: {keyword_name} = {keyword_score}")
                                                
                                                # ë‹¤ë¥¸ íŒ¨í„´ë„ ì‹œë„ (ì˜ˆ: "ì‹œì„¤5", "ì£¼ì°¨4" ë“±)
                                                keyword_match2 = re.match(r'([ê°€-í£]+)(\d+)', line)
                                                if keyword_match2:
                                                    keyword_name = keyword_match2.group(1)
                                                    keyword_score = int(keyword_match2.group(2))
                                                    keyword_scores[keyword_name] = keyword_score
                                                    print(f"í‚¤ì›Œë“œ ì ìˆ˜ ì¶”ì¶œ: {keyword_name} = {keyword_score}")
                                                
                                                # "+" íŒ¨í„´ ì²˜ë¦¬ (ì˜ˆ: "ê°€ê²© ë·° +3")
                                                keyword_match3 = re.match(r'([ê°€-í£]+)\s*([ê°€-í£]+)\s*\+(\d+)', line)
                                                if keyword_match3:
                                                    keyword1 = keyword_match3.group(1)
                                                    keyword2 = keyword_match3.group(2)
                                                    score = int(keyword_match3.group(3))
                                                    keyword_scores[keyword1] = score
                                                    keyword_scores[keyword2] = score
                                                    print(f"í‚¤ì›Œë“œ ì ìˆ˜ ì¶”ì¶œ: {keyword1}, {keyword2} = {score}")
                                                
                                                # ë‹¨ì¼ í‚¤ì›Œë“œ + íŒ¨í„´ (ì˜ˆ: "ì‹œì„¤ +3")
                                                keyword_match4 = re.match(r'([ê°€-í£]+)\s*\+(\d+)', line)
                                                if keyword_match4:
                                                    keyword_name = keyword_match4.group(1)
                                                    score = int(keyword_match4.group(2))
                                                    keyword_scores[keyword_name] = score
                                                    print(f"í‚¤ì›Œë“œ ì ìˆ˜ ì¶”ì¶œ: {keyword_name} = {score}")
                                                
                                                # "+" ê¸°í˜¸ë§Œ ìˆëŠ” ê²½ìš° (ë‹¤ìŒ ë¼ì¸ì—ì„œ ì ìˆ˜ ì°¾ê¸°)
                                                if line == '+':
                                                    print("'+' ê¸°í˜¸ ë°œê²¬, ë‹¤ìŒ ë¼ì¸ì—ì„œ ì ìˆ˜ ì°¾ê¸°")
                                                    # ë‹¤ìŒ ë¼ì¸ì—ì„œ ìˆ«ì ì°¾ê¸°
                                                    for next_line in lines:
                                                        next_line = next_line.strip()
                                                        # ìˆ«ìë§Œ ìˆëŠ”ì§€ í™•ì¸ (ì˜ˆ: "3")
                                                        if next_line.isdigit():
                                                            # ì´ì „ì— ë°œê²¬ëœ í‚¤ì›Œë“œë“¤ì— ì ìˆ˜ í• ë‹¹
                                                            score = int(next_line)
                                                            # ì´ì „ ë¼ì¸ë“¤ì—ì„œ í‚¤ì›Œë“œ ì°¾ê¸°
                                                            prev_keywords = []
                                                            for prev_line in lines:
                                                                prev_line = prev_line.strip()
                                                                if prev_line in ['ê°€ê²©', 'ë·°', 'ì‹œì„¤', 'ì£¼ì°¨', 'ì²­ê²°', 'ìœ„ì¹˜', 'ì„œë¹„ìŠ¤', 'ë¶„ìœ„ê¸°', 'í¸ì˜ì‹œì„¤']:
                                                                    prev_keywords.append(prev_line)
                                                            
                                                            for prev_keyword in prev_keywords:
                                                                keyword_scores[prev_keyword] = score
                                                                print(f"í‚¤ì›Œë“œ ì ìˆ˜ ì¶”ì¶œ: {prev_keyword} = {score}")
                                                            break
                                                
                                                # "+ìˆ«ì" íŒ¨í„´ ì²˜ë¦¬ (ì˜ˆ: "+3")
                                                if line.startswith('+') and line[1:].isdigit():
                                                    print(f"'+ìˆ«ì' íŒ¨í„´ ë°œê²¬: {line}")
                                                    score = int(line[1:])
                                                    # ì´ì „ ë¼ì¸ë“¤ì—ì„œ í‚¤ì›Œë“œ ì°¾ê¸°
                                                    prev_keywords = []
                                                    for prev_line in lines:
                                                        prev_line = prev_line.strip()
                                                        if prev_line in ['ê°€ê²©', 'ë·°', 'ì‹œì„¤', 'ì£¼ì°¨', 'ì²­ê²°', 'ìœ„ì¹˜', 'ì„œë¹„ìŠ¤', 'ë¶„ìœ„ê¸°', 'í¸ì˜ì‹œì„¤']:
                                                            prev_keywords.append(prev_line)
                                                    
                                                    for prev_keyword in prev_keywords:
                                                        keyword_scores[prev_keyword] = score
                                                        print(f"í‚¤ì›Œë“œ ì ìˆ˜ ì¶”ì¶œ: {prev_keyword} = {score}")
                                    
                                    if keyword_scores:
                                        break
                            except Exception as e:
                                continue
                    
                    # í‚¤ì›Œë“œ ì ìˆ˜ íŒ¨í„´ ì œê±° (ë¦¬ë·° í…ìŠ¤íŠ¸ì—ì„œ)
                    keyword_patterns_to_remove = [
                        r'ì‹œì„¤\s*ì£¼ì°¨\s*\+(\d+)',
                        r'ê°€ê²©\s*ì‹œì„¤\s*\+(\d+)',
                        r'ê°€ê²©\s*ë·°\s*\+(\d+)',
                        r'ì‹œì„¤\s*\+(\d+)',
                        r'ì£¼ì°¨\s*\+(\d+)',
                        r'ì²­ê²°\s*\+(\d+)',
                        r'ê°€ê²©\s*\+(\d+)',
                        r'ë·°\s*\+(\d+)',
                        r'ìœ„ì¹˜\s*\+(\d+)',
                        r'ì„œë¹„ìŠ¤\s*\+(\d+)',
                        r'ë¶„ìœ„ê¸°\s*\+(\d+)',
                        r'í¸ì˜ì‹œì„¤\s*\+(\d+)'
                    ]
                    
                    for pattern in keyword_patterns_to_remove:
                        review_text = re.sub(pattern, '', review_text)
                    
                    # ì‚¬ìš©ì ì •ë³´ ì œê±°
                    lines = review_text.split('\n')
                    cleaned_lines = []
                    
                    skip_patterns = [
                        'ê³¨ë“œ ë ˆë²¨', 'ì‹¤ë²„ ë ˆë²¨', 'ë¸Œë¡ ì¦ˆ ë ˆë²¨',
                        'í›„ê¸°', 'ë³„ì í‰ê· ', 'íŒ”ë¡œì›Œ',
                        'ë©”ë‰´ ë”ë³´ê¸°', 'ë ˆë²¨'
                    ]
                    
                    for line in lines:
                        line = line.strip()
                        if not line:
                            continue
                        
                        skip_line = False
                        for pattern in skip_patterns:
                            if pattern in line:
                                skip_line = True
                                break
                        
                        if line.isdigit() and len(line) <= 3:
                            skip_line = True
                        
                        if re.match(r'\d{4}\.\d{2}\.\d{2}', line):
                            skip_line = True
                        
                        if not skip_line:
                            cleaned_lines.append(line)
                    
                    review_text = ' '.join(cleaned_lines).strip()
                    
                    # "ì ‘ê¸°" í…ìŠ¤íŠ¸ ì œê±°
                    if "ì ‘ê¸°" in review_text:
                        review_text = review_text.split("ì ‘ê¸°")[0].strip()
                    
                    # "ë”ë³´ê¸°" í…ìŠ¤íŠ¸ ì œê±°
                    review_text = re.sub(r'ë”ë³´ê¸°\.?\.?\.?', '', review_text)
                    review_text = re.sub(r'\.\.\.\s*ë”ë³´ê¸°', '', review_text)
                    review_text = re.sub(r'ë”ë³´ê¸°', '', review_text)
                    
                    # ì—°ì†ëœ ê³µë°± ì œê±°
                    review_text = re.sub(r'\s+', ' ', review_text)
                    review_text = review_text.strip()
                    
                    if len(review_text) >= 5:
                        reviews.append({
                            'content': review_text,
                            'rating': 5,  # ê¸°ë³¸ê°’
                            'created_date': datetime.now().strftime("%Y-%m-%d"),
                            'writer': 'ì¹´ì¹´ì˜¤ë§µì‚¬ìš©ì',
                            'keyword_scores': keyword_scores  # í‚¤ì›Œë“œ ì ìˆ˜ ì¶”ê°€
                        })
                        print(f"ë¦¬ë·° ì €ì¥: {review_text[:50]}... (í‚¤ì›Œë“œ: {keyword_scores})")
                
                print("-" * 50)
            
            print(f"ì´ {len(reviews)}ê°œì˜ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
            return reviews
            
        except Exception as e:
            print(f"ë¦¬ë·° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def save_to_elasticsearch(self, reviews, camping_id, camping_name):
        """Elasticsearchì— ì €ì¥"""
        try:
            # í‚¤ì›Œë“œ ì ìˆ˜ í†µê³„ ê³„ì‚°
            keyword_stats = {}
            for review in reviews:
                keyword_scores = review.get('keyword_scores', {})
                for keyword, score in keyword_scores.items():
                    if keyword not in keyword_stats:
                        keyword_stats[keyword] = {'total_score': 0, 'count': 0}
                    keyword_stats[keyword]['total_score'] += score
                    keyword_stats[keyword]['count'] += 1
            
            # í‰ê·  ì ìˆ˜ ê³„ì‚°
            for keyword in keyword_stats:
                keyword_stats[keyword]['average_score'] = round(
                    keyword_stats[keyword]['total_score'] / keyword_stats[keyword]['count'], 1
                )
            
            print(f"í‚¤ì›Œë“œ ì ìˆ˜ í†µê³„: {keyword_stats}")
            
            for i, review in enumerate(reviews):
                doc = {
                    'revId': None,
                    'contentId': camping_id,
                    'memberId': 1,
                    'writer': review['writer'],
                    'content': review['content'],
                    'createdAt': datetime.now().isoformat(),
                    'updatedAt': datetime.now().isoformat(),
                    'score': review['rating'],
                    'keywordIds': [],
                    'campingName': camping_name,
                    'source': 'kakao_map',
                    'keywordScores': review.get('keyword_scores', {}),  # í‚¤ì›Œë“œ ì ìˆ˜ ì¶”ê°€
                    'keywordStats': keyword_stats  # í‚¤ì›Œë“œ í†µê³„ ì¶”ê°€
                }
                
                response = self.es.index(index=self.index_name, body=doc)
                print(f"Elasticsearch ë¦¬ë·° {i+1} ì €ì¥ ì™„ë£Œ: {response['result']}")
            
            self.es.indices.refresh(index=self.index_name)
            print(f"ìº í•‘ì¥ '{camping_name}': {len(reviews)}ê°œ ë¦¬ë·° Elasticsearch ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            print(f"Elasticsearch ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def read_camping_data_from_excel(self):
        """Excel íŒŒì¼ì—ì„œ ìº í•‘ì¥ ë°ì´í„° ì½ê¸°"""
        try:
            # Excel íŒŒì¼ ê²½ë¡œ
            excel_path = "../../camping_data.xlsx"
            
            # Excel íŒŒì¼ ì½ê¸°
            import pandas as pd
            df = pd.read_excel(excel_path)
            
            print(f"Excel íŒŒì¼ ì½ê¸° ì„±ê³µ!")
            print(f"ì´ {len(df)}ê°œì˜ ìº í•‘ì¥ ë°ì´í„°ë¥¼ ì½ì–´ì™”ìŠµë‹ˆë‹¤.")
            
            camping_data = []
            for index, row in df.iterrows():
                camping_id = row['contentId']
                camping_name = row['facltNm']
                address = row['addr1'] if pd.notna(row['addr1']) else "ì£¼ì†Œ ì •ë³´ ì—†ìŒ"
                
                camping_data.append((camping_id, camping_name, address))
            
            print(f"ì´ {len(camping_data)}ê°œì˜ ìº í•‘ì¥ ë°ì´í„°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
            return camping_data
            
        except Exception as e:
            print(f"Excel íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            return []
    
    def search_kakao_place(self, camping_name):
        """ì¹´ì¹´ì˜¤ë§µ APIë¡œ ìº í•‘ì¥ ê²€ìƒ‰"""
        try:
            import requests
            
            # ì¹´ì¹´ì˜¤ë§µ API ì„¤ì •
            kakao_api_key = "22a3f23874d2dacc284c6ab7eea89e10"
            kakao_search_url = "https://dapi.kakao.com/v2/local/search/keyword.json"
            kakao_place_url = "https://place.map.kakao.com/"
            
            headers = {
                'Authorization': f'KakaoAK {kakao_api_key}'
            }
            
            params = {
                'query': camping_name,
                'category_group_code': 'AD5',  # ìˆ™ë°• ì¹´í…Œê³ ë¦¬
                'size': 1
            }
            
            print(f"ì¹´ì¹´ì˜¤ë§µ APIë¡œ ê²€ìƒ‰ ì¤‘: {camping_name}")
            response = requests.get(kakao_search_url, headers=headers, params=params)
            
            if response.status_code == 200:
                data = response.json()
                if data['documents']:
                    place = data['documents'][0]
                    place_id = place['id']
                    # ë¦¬ë·° í˜ì´ì§€ë¡œ ì§ì ‘ ì´ë™ (#comment ì¶”ê°€)
                    place_url = f"{kakao_place_url}{place_id}#comment"
                    print(f"ì¥ì†Œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤: {place['place_name']} (ID: {place_id})")
                    return place_url
                else:
                    print(f"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤: {camping_name}")
                    return None
            else:
                print(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"ì¹´ì¹´ì˜¤ë§µ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def run(self, start_index=0, end_index=None, person_number=None):
        """í¬ë¡¤ë§ ì‹¤í–‰"""
        # ì‚¬ëŒ ë²ˆí˜¸ ì„¤ì •
        self.person_number = person_number or 'unknown'
        print(f"4325ê°œ ìº í•‘ì¥ ë¦¬ë·° í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ì‚¬ëŒ {self.person_number})")
        
        try:
            # í¬ë¡¬ë“œë¼ì´ë²„ ì„¤ì •
            self.driver = webdriver.Chrome(options=self.chrome_options)
            print("í¬ë¡¬ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ!")
            
            # Excel íŒŒì¼ì—ì„œ ìº í•‘ì¥ ë°ì´í„° ì½ê¸°
            camping_sites = self.read_camping_data_from_excel()
            
            if not camping_sites:
                print("ìº í•‘ì¥ ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ì¸ë±ìŠ¤ ë²”ìœ„ ì„¤ì •
            if end_index is None:
                end_index = len(camping_sites)
            
            camping_sites = camping_sites[start_index:end_index]
            
            print(f"ì´ {len(camping_sites)}ê°œì˜ ìº í•‘ì¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. (ì¸ë±ìŠ¤: {start_index}~{end_index-1})")
            
            all_reviews = []  # ëª¨ë“  ë¦¬ë·°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
            
            for i, (camping_id, camping_name, address) in enumerate(camping_sites, 1):
                print(f"[{i}/{len(camping_sites)}] {camping_name} ì²˜ë¦¬ ì¤‘...")
                
                # ì¹´ì¹´ì˜¤ë§µì—ì„œ ìº í•‘ì¥ ê²€ìƒ‰
                place_url = self.search_kakao_place(camping_name)
                if not place_url:
                    print(f" - {camping_name}: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                    continue
                
                # ë¦¬ë·° ì¶”ì¶œ
                reviews = self.extract_reviews_with_more(place_url)
                if not reviews:
                    print(f" - {camping_name}: ë¦¬ë·° ì—†ìŒ")
                    continue
                
                print(f" - {camping_name}: {len(reviews)}ê°œ ë¦¬ë·° ìˆ˜ì§‘")
                
                # Elasticsearchì— ì €ì¥
                self.save_to_elasticsearch(reviews, camping_id, camping_name)
                
                # ê°œë³„ ìº í•‘ì¥ CSV íŒŒì¼ ì €ì¥
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                csv_filename = f"{self.output_dir}/reviews_{camping_id}_{timestamp}.csv"
                
                # í‚¤ì›Œë“œ ì ìˆ˜ í•„ë“œë“¤ì„ ë™ì ìœ¼ë¡œ ì¶”ê°€
                all_keywords = set()
                for review in reviews:
                    all_keywords.update(review.get('keyword_scores', {}).keys())
                
                fieldnames = ['camping_id', 'camping_name', 'writer', 'content', 'rating', 'created_date']
                fieldnames.extend([f'keyword_{keyword}' for keyword in sorted(all_keywords)])
                
                with open(csv_filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                    writer.writeheader()
                    
                    for review in reviews:
                        row = {
                            'camping_id': camping_id,
                            'camping_name': camping_name,
                            'writer': review['writer'],
                            'content': review['content'],
                            'rating': review['rating'],
                            'created_date': review['created_date']
                        }
                        
                        # í‚¤ì›Œë“œ ì ìˆ˜ ì¶”ê°€
                        keyword_scores = review.get('keyword_scores', {})
                        for keyword in sorted(all_keywords):
                            row[f'keyword_{keyword}'] = keyword_scores.get(keyword, '')
                        
                        writer.writerow(row)
                
                print(f"CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_filename}")
                
                # ì „ì²´ ë¦¬ë·° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                for review in reviews:
                    all_reviews.append({
                        'camping_id': camping_id,
                        'camping_name': camping_name,
                        'writer': review['writer'],
                        'content': review['content'],
                        'rating': review['rating'],
                        'created_date': review['created_date'],
                        'keyword_scores': review.get('keyword_scores', {})
                    })
                
                # ìš”ì²­ ê°„ê²© ì¡°ì ˆ (ì„œë²„ ë¶€í•˜ ë°©ì§€)
                import random
                time.sleep(random.uniform(3, 7))
            
            # í†µí•© CSV íŒŒì¼ ì €ì¥
            if all_reviews:
                print(f"\nğŸ“Š ì´ {len(all_reviews)}ê°œ ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ!")
                
                # í†µí•© CSV íŒŒì¼ ì €ì¥ (ì‚¬ëŒ ë²ˆí˜¸ í¬í•¨)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                # ì‚¬ëŒ ë²ˆí˜¸ë¥¼ íŒŒì¼ëª…ì— í¬í•¨ (ì „ì—­ ë³€ìˆ˜ë¡œ ê´€ë¦¬)
                person_number = getattr(self, 'person_number', 'unknown')
                csv_filename = f"{self.output_dir}/all_reviews_person{person_number}_{timestamp}.csv"
                
                # í‚¤ì›Œë“œ ì ìˆ˜ í•„ë“œë“¤ì„ ë™ì ìœ¼ë¡œ ì¶”ê°€
                all_keywords = set()
                for review_data in all_reviews:
                    all_keywords.update(review_data.get('keyword_scores', {}).keys())
                
                fieldnames = ['camping_id', 'camping_name', 'writer', 'content', 'rating', 'created_date']
                fieldnames.extend([f'keyword_{keyword}' for keyword in sorted(all_keywords)])
                
                with open(csv_filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                    writer.writeheader()
                    
                    for review_data in all_reviews:
                        row = {
                            'camping_id': review_data['camping_id'],
                            'camping_name': review_data['camping_name'],
                            'writer': review_data['writer'],
                            'content': review_data['content'],
                            'rating': review_data['rating'],
                            'created_date': review_data['created_date']
                        }
                        
                        # í‚¤ì›Œë“œ ì ìˆ˜ ì¶”ê°€
                        keyword_scores = review_data.get('keyword_scores', {})
                        for keyword in sorted(all_keywords):
                            row[f'keyword_{keyword}'] = keyword_scores.get(keyword, '')
                        
                        writer.writerow(row)
                
                print(f"ğŸ“„ í†µí•© CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_filename}")
                
        except Exception as e:
            print(f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            if self.driver:
                self.driver.quit()
            print("í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±
    parser = argparse.ArgumentParser(description='ì¹´ì¹´ì˜¤ë§µ ë¦¬ë·° í¬ë¡¤ëŸ¬')
    parser.add_argument('--batch', type=int, help='ë°°ì¹˜ ë²ˆí˜¸ (1-7)')
    parser.add_argument('--start', type=int, help='ì‹œì‘ ì¸ë±ìŠ¤')
    parser.add_argument('--size', type=int, help='ì²˜ë¦¬í•  ìº í•‘ì¥ ìˆ˜')
    parser.add_argument('--test', action='store_true', help='í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì²˜ìŒ 10ê°œë§Œ)')
    
    args = parser.parse_args()
    
    crawler = SimpleMoreCrawler()
    
    # 7ëª…ì´ ë‚˜ëˆ„ì–´ì„œ í¬ë¡¤ë§í•  ì¸ë±ìŠ¤ ë²”ìœ„ ì„¤ì •
    total_campings = 4325
    people_count = 7
    camping_per_person = total_campings // people_count
    remainder = total_campings % people_count
    
    # ê° ì‚¬ëŒë³„ ì¸ë±ìŠ¤ ë²”ìœ„ ê³„ì‚°
    ranges = []
    start = 0
    for i in range(people_count):
        end = start + camping_per_person
        if i < remainder:  # ë‚˜ë¨¸ì§€ë¥¼ ì•ìª½ ì‚¬ëŒë“¤ì—ê²Œ ë¶„ë°°
            end += 1
        ranges.append((start, end))
        start = end
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ëŒ€í™”í˜• ëª¨ë“œ
    if args.batch or args.start is not None or args.test:
        # ëª…ë ¹í–‰ ì¸ìˆ˜ ëª¨ë“œ
        if args.test:
            start_index = 0
            end_index = 10
            person_number = "test"
            print(f"í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì¸ë±ìŠ¤ {start_index} ~ {end_index-1}")
        elif args.batch:
            if 1 <= args.batch <= 7:
                person_idx = args.batch - 1
                start_index, end_index = ranges[person_idx]
                person_number = str(args.batch)
                print(f"ë°°ì¹˜ {args.batch} ì„ íƒ: ì¸ë±ìŠ¤ {start_index} ~ {end_index-1} ({end_index-start_index}ê°œ ìº í•‘ì¥)")
            else:
                print("ë°°ì¹˜ ë²ˆí˜¸ëŠ” 1-7 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
                exit(1)
        elif args.start is not None:
            start_index = args.start
            if args.size:
                end_index = start_index + args.size
            else:
                end_index = start_index + 618  # ê¸°ë³¸ê°’
            person_number = f"custom_{start_index}"
            print(f"ì»¤ìŠ¤í…€ ë²”ìœ„: ì¸ë±ìŠ¤ {start_index} ~ {end_index-1} ({end_index-start_index}ê°œ ìº í•‘ì¥)")
        
        # í¬ë¡¤ë§ ì‹¤í–‰
        crawler.run(start_index=start_index, end_index=end_index, person_number=person_number)
        
    else:
        # ëŒ€í™”í˜• ëª¨ë“œ (ê¸°ì¡´ ë°©ì‹)
        print(f"ì´ ìº í•‘ì¥ ìˆ˜: {total_campings}")
        print(f"ë¶„ë‹´ ì¸ì›: {people_count}ëª…")
        print(f"1ì¸ë‹¹ ì²˜ë¦¬í•  ìº í•‘ì¥ ìˆ˜: {camping_per_person}ê°œ")
        print(f"ë‚˜ë¨¸ì§€: {remainder}ê°œ")
        
        print("\n=== ê° ì‚¬ëŒë³„ ì²˜ë¦¬ ë²”ìœ„ ===")
        for i, (start_idx, end_idx) in enumerate(ranges, 1):
            count = end_idx - start_idx
            print(f"ì‚¬ëŒ {i}: ì¸ë±ìŠ¤ {start_idx} ~ {end_idx-1} ({count}ê°œ)")
        
        # ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ì²˜ë¦¬í•  ë²”ìœ„ ì„ íƒ
        print("\n=== í¬ë¡¤ë§ ë²”ìœ„ ì„ íƒ ===")
        for i, (start_idx, end_idx) in enumerate(ranges, 1):
            count = end_idx - start_idx
            print(f"{i}: ì‚¬ëŒ {i} (ì¸ë±ìŠ¤ {start_idx}~{end_idx-1}, {count}ê°œ)")
        print("0: í…ŒìŠ¤íŠ¸ìš© (ì²˜ìŒ 10ê°œë§Œ)")
        
        try:
            choice = input("\nì²˜ë¦¬í•  ë²”ìœ„ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-7, 0): ").strip()
            
            if choice == "0":
                # í…ŒìŠ¤íŠ¸ìš© - ì²˜ìŒ 10ê°œë§Œ
                start_index = 0
                end_index = 10
                person_number = "test"
                print(f"í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì¸ë±ìŠ¤ {start_index} ~ {end_index-1}")
            elif choice in ["1", "2", "3", "4", "5", "6", "7"]:
                person_idx = int(choice) - 1
                start_index, end_index = ranges[person_idx]
                person_number = choice
                print(f"ì‚¬ëŒ {choice} ì„ íƒ: ì¸ë±ìŠ¤ {start_index} ~ {end_index-1} ({end_index-start_index}ê°œ ìº í•‘ì¥)")
            else:
                print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ê¸°ë³¸ê°’(í…ŒìŠ¤íŠ¸ìš©)ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                start_index = 0
                end_index = 10
                person_number = "test"
            
            # í¬ë¡¤ë§ ì‹¤í–‰
            crawler.run(start_index=start_index, end_index=end_index, person_number=person_number)
            
        except KeyboardInterrupt:
            print("\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")